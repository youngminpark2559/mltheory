<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
   <HEAD>
      <TITLE>My first HTML document</TITLE>
      <style rel="stylesheet" type="text/css">
body {
 font-size: 20px;
 
 margin-top: 50px;
    margin-bottom: 50px;
    margin-right: 80px;
    margin-left: 100px;
    
    padding-top: 50px;
    padding-bottom: 50px;
    padding-right: 80px;
    padding-left: 80px;
    
    line-height:35px;
}
img {
 width:900px;
}
</style>
      <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    "HTML-CSS" : {
        availableFonts : ["STIX"],
        preferredFont : "STIX",
        webFont : "STIX-Web",
        imageFont : null
    }
});
</script>
     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">    
    MathJax.Hub.Config({
        HTML: ["input/TeX","output/HTML-CSS"],
        TeX: { extensions: ["AMSmath.js","AMSsymbols.js"], 
               equationNumbers: { autoNumber: "AMS" } },
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: { inlineMath: [ ['$$$','$$$'] ],
                   displayMath: [ ['$$$$','$$$$'] ],
                   processEscapes: true },
        "HTML-CSS": { availableFonts: ["TeX"],
                      linebreaks: { automatic: true } }
    });
</script>
   </HEAD>
   <BODY>

<xmp>

================================================================================
* Feature extraction

original_feature_vector=[x_1,x_2,...x_N]
dim_reduced_feat_vector=linear_feature_extraction(original_feature_vector)
print(dim_reduced_feat_vector)
# [y_1,y_2,...y_M]

================================================================================
</xmp><img src="https://raw.githubusercontent.com/youngmtool/mltheory/master/jjpr/pic/2018-06-04 10-08-45.png"><xmp>

* $$$X = f(X) = \mathbb{Y}^M = \mathbb{W}^{M\times N} \mathbb{X}^N$$$   
* dim_reduced_feat_vector = transform_mat $$$\times$$$ original_feature_vector

================================================================================
* W can be very various based on your purposes which feature you want to more preserve

* Purpose1: signal representation
- Precise data representaion in lower dimension
- W is found by PCA

* Purpose2: classification
- Easier classification in lower dimension
- W is found by LDA

================================================================================
</xmp><img src="https://raw.githubusercontent.com/youngmtool/mltheory/master/jjpr/pic/2018-06-04 10-37-49.png"><xmp>

* 2D feature vector

* 1D feature vector for better signal representation using PCA
- Variance of each feature is preserved

* 1D feature vector for better classification using LDA
- Easier classification

</xmp>
   </BODY>
</HTML>
