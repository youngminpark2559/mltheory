<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
   <HEAD>
      <TITLE>My first HTML document</TITLE>
      <style rel="stylesheet" type="text/css">
body {
 font-size: 25px;
 
 margin-top: 50px;
    margin-bottom: 50px;
    margin-right: 150px;
    margin-left: 40px;
    
    padding-top: 50px;
    padding-right: 30px;
    padding-bottom: 50px;
    padding-left: 40px;
    
    line-height:1.5em
}
</style>
      <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    "HTML-CSS" : {
        availableFonts : ["STIX"],
        preferredFont : "STIX",
        webFont : "STIX-Web",
        imageFont : null
    }
});
</script>
     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">    
    MathJax.Hub.Config({
        HTML: ["input/TeX","output/HTML-CSS"],
        TeX: { extensions: ["AMSmath.js","AMSsymbols.js"], 
               equationNumbers: { autoNumber: "AMS" } },
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                   displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                   processEscapes: true },
        "HTML-CSS": { availableFonts: ["TeX"],
                      linebreaks: { automatic: true } }
    });
</script>
   </HEAD>
   <BODY>
10-01 HMM<br/>
<br/>

<img src="https://raw.githubusercontent.com/youngmtool/machinelearning/master/hwlee/pics/10-01.png"> <br/><br/>

@<br/>
$r_{ij}(n)$ : state i 에서 출발해서 시간 n 일때 state j 에 있을 확률이다. <br/>
markov chain 이 single recurrent class 를 가지고 있고, 그 recurrent class 가 aperiodic 한다는 두 조건 아래에서 n 이 무한대로 가면 이 확률 $r_{ij}(n)$ 이 initial state i 에 상관없이 $\pi_{j}$ 로 수렴한다. <br/>
<br/>
aperiodic 관점에서 보면 시간 n 이 무한대로 가면 처음에 어디(i)에서 출발 했든지 간에 state j 에 있을 확률이 $\pi_{j}$ 의 값으로 convergence 한다. <br/>
<br/>
@<br/>
p1<br/>
linear system 이나 미분방정식에서 많이 등장하는 $e_{-t}\sin{t}$ 라는 함수를 가정해보자. <br/>
t=0 일때 0이고 t 가 무한대로 가면 0으로 convergence 한다. 변화하지 않고 정상상태에 있게된다. 0으로 수렴하기 전의 모양을 transient period (잠복기) 라고 한다. <br/>
p1 e<br/>
<br/>
@<br/>
p2<br/>
MC 하나를 가정하자.<br/>
두 state 는 transient state 이다. 아래 두개는 recurrent 하다. 위에서 돌다가 아래쪽 노드로 들어오면 빠져나가지 않는다. 들어가기까지 걸리는 시간에 관심을 둘 수 있다. MC 가 위쪽 노드에서 출발한다면 아랫쪽 노드들 중 하나로 들어갈텐데 각각 노드로 들어갈 확률이 어떻게 되는가 에 관심을 둘 수 있다. 아랫쪽 recurrent 한 node 에 들어가기 전의 transient 한 node 들의 behavior 를 공부하는게 transient behavior 공부의 목적이다. <br/>
p2 e<br/>
<br/>
@<br/>
p3<br/>
이런 MC 을 가정하자.<br/>
돌아가다가 최종적으로 중단 node 에 들어갈것이다. 그리고 시간이 지나면서 어떻게 되는가 에 관심을 두는 것이 status behavior 이다. <br/>
p3 e<br/>
<br/>
@<br/>
transient behavior 중에서 absortion probability 를 알아보자.<br/>
MC 의 recurrent class 에 들어가면 빠져나올수 없다. 이러한 recurrent class 를 통칭하여 흡수되어 빠져나올수 없다는 의미로 absorbing state 라고 한다. absortion 되기 까지 시간이 absortion time 이고 obsorbing 될 확률이 absortion probability 이다. <br/>
<br/>
@<br/>
Gambler's ruin : gambling 에서 최종적으로 망할확률, 성공확률을 MC 을 이용하여 분석해볼것이다. <br/>
<br/>
@<br/>
state frequancy : $r_{ij}(n)$ 은 시간 n 일때 state 가 j 일 확률이라고 했다. state frequancy 는 시간 n 까지 가는 동안 state j 가 방문된 횟수 혹은 빈도를 의미한다. 전체 n 번의 transient 이 일어났다면, 혹은, n 개의 state 를 방문했다면, n 번중에서 state j 를 몇번 방문했느냐, 특정 transient 가 얼마나 자주 일어났느냐 의 의미이다. <br/>
<br/>
@<br/>
state frequancy <br/>
state behavior 를 얘기 할때는 거의 아래와 같은 조건을 가정한다.<br/>
Discrete Time markov Chain 이 <br/>
with a 이고 <br/>
single aperiodic recurrent class 만 가진다. <br/>
<br/>
@<br/>
initial state i 에서 출발해서 시간 n 이 될때 까지 state j 를 방문한 빈도 혹은 횟수는 random variable $V_{ij}(n)$ 일 것이다. 따라서, 그 횟수의 expectation 을 따져보자.<br/>
<br/>
$V_{ij}(n)$ 은 시간 1에서 n 까지 가는동안 j 를 방문한 횟수를 다 더하고 Expectation 을 취해주면 된다.<br/>
Indicator function 을 사용한다. Indicator function $I_{\{A\}}$ 는 event A 가 발생하면 1이고 일어나지 않으면 0이다. 따라서, 다음과 같이 표현할수 있다.<br/>
$V_{ij}(n)=E[\sum\limits_{t=1}^{n} I_{\{X_{t}=j|X_{0}=i\}}]$<br/>
$X_{0}$ : initial state <br/>
$X_{0}$ 가 i 에서 출발했을때 시각 t 에서 state 가 j 이면 1 그렇지 않으면 0 이라는 뜻이다. <br/>
따라서 시간 t =1 에서 t=n 까지 다 더하면 state j 를 방문한 총 횟수가 계산된다. <br/>
<br/>
event A 가 있다면 $I_{\{A\}}$ 가 random variable 이다. <br/>
$E[I_{\{A\}}]$ 은 $1\times$(1이 발생할 확률, 즉, A가 발생할 확률)+$0\times$(A가 일어나지 않을 확률) 이므로 A가 발생활 확률 P(A) 이다.  <br/>
<br/>
sum 의 expectation 은 expectation 의 sum 인 성질을 이용해 다음과 같이 정리한다.<br/>
$V_{ij}(n)=E[\sum\limits_{t=1}^{n} I_{\{X_{t}=j|X_{0}=i\}}]$<br/>
$V_{ij}(n)=\sum\limits_{t=1}^{n} E[I_{\{X_{t}=j|X_{0}=i\}}]$<br/>
$E[I_{\{A\}}]$ 은 event A의 확률 P(A) 임을 이용한다. <br/>
event ${\{X_{t}=j|X_{0}=i\}}$ 의 확률은 i에서 출발해서 시각 t 에서 j 일 확률인 $r_{ij}(t)$ 이다. 따라서\<br/>
$V_{ij}(n)=\sum\limits_{t=1}^{n} r_{ij}(t)$ <br/>
<br/>
빈도로 나타내 보자. initial state $X_{0}=i$ 에서 출발해서 시간 1부터 n까지 총 n 개의 state 를 방문할것이다. 그 중에서 state j 를 방문한게 몇번이냐를 표현하는 $\frac{1}{n}V_{ij}(n)$ 를 구해보자. <br/>
그리고 위의 수식에서 시간 n 이 무한대로 갈때 $\lim_{n\to\infty} \frac{1}{n}V_{ij}(n)$ 를 생각해보자. <br/>
<br/>
위에 구한 수식의 관계로 부터 다음과 같이 쓸수 있다.<br/>
$\lim\limits_{n\to\infty} \frac{1}{n}V_{ij}(n) = \lim\limits_{n\to\infty} \frac{1}{n} \sum\limits_{t=1}^{n} r_{ij}(t)$<br/>
처음에 했던 가정으로 부터 $r_{ij}(t)$ 은 t 가 무한대로 가면 $\pi_{j}$ 로 convergence 한다. 따라서,<br/>
$\lim\limits_{n\to\infty} \frac{1}{n}V_{ij}(n) = \lim\limits_{n\to\infty} \frac{1}{n} \sum\limits_{t=1}^{n} r_{ij}(t)=\pi_{j}$ 이다.<br/>
<br/>
@<br/>
$\pi_{j}$ 는 시간 n 이 무한대로 갈때(MC 이 많이 진행됐을때) state j 에 있을 확률이었다.<br/>
$\lim\limits_{n\to\infty} \frac{1}{n}V_{ij}(n) = \lim\limits_{n\to\infty} \frac{1}{n} \sum\limits_{t=1}^{n} r_{ij}(t)=\pi_{j}$ 를 보면 $\pi_{j}$ 를 다른식으로도 해석할 수 있는데, 시간 n 이 무한대로 갈때(MC 이 많이 진행됐을때) state j 가 방문된 빈도라고 볼수 있다는 것이다. <br/>
<br/>
@<br/>
p4<br/>
이제 transient frequancy 를 알아 보자. i, j node 로 구성되어 있는 MC 을 그려보자. <br/>
출발하고 돌아다니면서 MC 가 진행된다. 그 때 j 를 방문한 빈도를 위에서 고찰해봤다면, transient frequancy 는 transient 이 일어난 frequancy 를 따지는게 transient frequancy 이다. <br/>
p4 e<br/>
<br/>
@<br/>
transient frequancy 는 위에서 봤던 똑같은 condition <br/>
1. Discrete Time Markov Chain is with a<br/>
2. Discrete Time Markov Chain has a single aperiodic recurrent class<br/>
과 더불어서 <br/>
MC 가 시간 n 까지 진행됐을때, state j 에서 state k 로 transient 이 일어난 횟수(random variable, $q_{jk}(n)$ ) 의 expectation 이다.<br/>
<br/>
@<br/>
결과를 놓고 고찰해 보자. j 에서 k 로 transient 이 일어나려면 일단 state 가 j 에 있어야 한다. 이 때, 시간 n 이 무한대로 간다면 state j 에 있을 확률은 $\pi_{j}$ 이다. j 에서 k 로 transient 이 일어날 확률은 $\pi_{j} P_{jk}$ 가 된다.<br/>
<br/>
@<br/>
p5<br/>
initial state 가 randomly 하게 출발 했을때, 시간 1 까지 흘렀을때 j에서 k로 transient 이 한번 발생하려면 시간 0일때 state 가 j 에 있어야 하고 시간 1일때 state 가 k 에 있어야 한다. <br/>
즉, $X_{0}=j \cap X_{1}=k$ 이면 j 에서 k 로 transient 가 일어나는 것이다. <br/>
p5 e<br/>
<br/>
@<br/>
위의 내용을 아래에 적용해본다.<br/>
$q_{jk}(n)$ 은 바로 이전 시각이 j 였다가 $X_{t-1}=j$ 그 다음 시점에서의 state 가 k 가 되는 $X_{t}=k$ 인 Indicator function 을 t=1 에서 t=n 까지 진행하면서 더한것의 expectation 이 $q_{jk}(n)$ 의 정의이다.<br/>
$q_{jk}(n)=E[\sum\limits_{t=1}^{n} I_{\{X_{t}=k, X_{t-1}=j\}}]$<br/>
<br/>
@<br/>
initial state 는 일단 고려하지 않는다. 그러면 다음과 같이 수식을 정리 할수 있다.<br/>
$q_{jk}(n)=E[\sum\limits_{t=1}^{n} I_{\{X_{t}=k, X_{t-1}=j\}}]$<br/>
$q_{jk}(n)=\sum\limits_{t=1}^{n} E[I_{\{X_{t}=k, X_{t-1}=j\}}]$<br/>
$q_{jk}(n)=\sum\limits_{t=1}^{n} P(X_{t}=k, X_{t-1}=j)$<br/>
$q_{jk}(n)=\sum\limits_{t=1}^{n} P(X_{t}=k \cap X_{t-1}=j)$<br/>
우리는 j 에서 k 로 transient 이 일어날 확률 $P_{jk}$ 를 알고 있다. 이때, $\pi_{j}P_{jk}$ 를 도출하고 싶다. <br/>
conditional probability 의 Definition 을 이용해 다음과 같이 변형한다.<br/>
$q_{jk}(n)=\sum\limits_{t=1}^{n} P(X_{t-1}=j) P(X_{t}=k|X_{t-1}=j)$<br/>
우리는 $P(X_{t}=k|X_{t-1}=j)=P_{kj}$ 임을 알고있다. 따라서,<br/>
$q_{jk}(n)=\sum\limits_{t=1}^{n} P(X_{t-1}=j) P_{jk}$<br/>
initial state 를 모를때도 수식을 진행할 수 있다. <br/>
initial state 를 모르는 상태에서 시각이 t-1 일때, state 가 j 에 있을 확률 $P(X_{t-1}=j)$ 이 어떻게 되는가?<br/>
$P(X_{t-1}=j)$ 에 total probability theorem 을 써서 정리하면서 알아낼 수 있다.<br/>
더 간편한 방법은 $X_{0}=i$ 처럼 initial state 를 i 라고 가정으르 하고 진행하는게 더 간편하다. <br/>
그런데 여기서에서는 total probability theorem 을 써본다<br/>
<br/>
그리고 위 수식에 total probability theorem 을 적용해서 정리해보자.<br/>
$q_{jk}(n)= \sum\limits_{t=1}^{n} \sum\limits_{i=1}^{m} P(X_{0}=i) P(X_{t-1}=j|X_{0}=i) P_{jk}$<br/>
$q_{jk}(n)= \sum\limits_{t=1}^{n} \sum\limits_{i=1}^{m} P(X_{0}=i) r_{ij}(t-1) P_{jk}$<br/>
빈도를 따져보기 위해서 lim 를 취한다.<br/>
$\lim\limits_{n\to\infty} \frac{1}{n} q_{jk}(n) = \lim\limits_{n\to\infty} \frac{1}{n} \sum\limits_{t=1}^{n} \sum\limits_{i=1}^{m} P(X_{0}=i) r_{ij}(t-1) P_{jk}$<br/>
t 가 무한대로 가면 $\sum\limits_{i=1}^{m} P(X_{0}=i) r_{ij}(t-1) P_{jk}$ 에서 t 에 의해 변하는 부분은 $r_{ij}(t-1)$ 부분밖에 없고 $\pi_{j}$ 로 convergence 한다. $\sum\limits_{i=1}^{m} P(X_{0}=i)=1$ 이므로 $\sum\limits_{i=1}^{m} P(X_{0}=i) r_{ij}(t-1) P_{jk}$ 은 $\pi_{j}P_{jk}$ 로 convergence 한다.<br/>
<br/>
43<br/>
      
   </BODY>
</HTML>
