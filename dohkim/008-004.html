<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
   <HEAD>
      <TITLE>My first HTML document</TITLE>
      <style rel="stylesheet" type="text/css">
body {
 font-size: 25px;
 
 margin-top: 50px;
    margin-bottom: 50px;
    margin-right: 80px;
    margin-left: 80px;
    
    padding-top: 50px;
    padding-bottom: 50px;
    padding-right: 80px;
    padding-left: 80px;
    
    line-height:1.6em
}
</style>
      <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    "HTML-CSS" : {
        availableFonts : ["STIX"],
        preferredFont : "STIX",
        webFont : "STIX-Web",
        imageFont : null
    }
});
</script>
     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">    
    MathJax.Hub.Config({
        HTML: ["input/TeX","output/HTML-CSS"],
        TeX: { extensions: ["AMSmath.js","AMSsymbols.js"], 
               equationNumbers: { autoNumber: "AMS" } },
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                   displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                   processEscapes: true },
        "HTML-CSS": { availableFonts: ["TeX"],
                      linebreaks: { automatic: true } }
    });
</script>
   </HEAD>
   <BODY>
008-004. dataframe manipulating data
<xmp>
@
% Pandas provides almost all methods which are provided by numpy 2 dimensional array
% Additionally, pandas provides various methods for data process and data transformation
% For more entire list, see following site
% https://pandas.pydata.org/pandas-docs/stable/api.html

@
% The most simplest data analysis is counting
% You can use count()
% It doesn't count NaN value
s = pd.Series(range(10))
% 0    0
% 1    1
% 2    2
% 3    3
% 4    4
% 5    5
% 6    6
% 7    7
% 8    8
% 9    9
% dtype: int32
s[3] = np.nan
s
% 0    0.0
% 1    1.0
% 2    2.0
% 3    NaN
% 4    4.0
% 5    5.0
% 6    6.0
% 7    7.0
% 8    8.0
% 9    9.0
% dtype: float64
s.count()
% 9

@
% In dataframe, it counts data per column
% So, it's useful when you find NaN

np.random.seed(2)
df = pd.DataFrame(np.random.randint(5, size=(4, 4)), dtype=float)
%   0	1	2	3
% 0	0.0	0.0	3.0	2.0
% 1	3.0	0.0	2.0	1.0
% 2	3.0	2.0	4.0	4.0
% 3	4.0	3.0	4.0	2.0

df.iloc[2,3] = np.nan
%   0	1	2	3
% 0	0.0	0.0	3.0	2.0
% 1	3.0	0.0	2.0	1.0
% 2	3.0	2.0	4.0	NaN
% 3	4.0	3.0	4.0	2.0

df.count()
% Row 3's count is 3
% 0    4
% 1    4
% 2    4
% 3    3
% dtype: int64

@
% Practice 1
% Load Titinic data in form of dataframe
% You should installed seaborn package to proceed steps
import seaborn as sns
titanic = sns.load_dataset("titanic")

% 1. Bring passenger data per row


@
% You can the number of appearance of specific value if value is kind of integer, string, categorical value
np.random.seed(1)
s2 = pd.Series(np.random.randint(6, size=100))
% 0     5
% 1     3
% 2     4
% 3     0
% 4     1
% 5     3
% 6     5
% 7     0
% 8     0
% 9     1
% 10    4
% 11    5
% 12    4
% 13    1
% 14    2
% 15    4
% 16    5
% 17    2
% 18    4
% 19    3
% 20    4
% 21    2
% 22    4
% 23    5
% 24    2
% 25    4
% 26    1
% 27    1
% 28    0
% 29    5
%      ..
% 70    3
% 71    5
% 72    4
% 73    3
% 74    5
% 75    1
% 76    3
% 77    0
% 78    0
% 79    2
% 80    2
% 81    1
% 82    3
% 83    4
% 84    2
% 85    0
% 86    0
% 87    1
% 88    1
% 89    5
% 90    3
% 91    0
% 92    0
% 93    5
% 94    5
% 95    4
% 96    5
% 97    2
% 98    4
% 99    3
% Length: 100, dtype: int32

s2.tail()
% 95    4
% 96    5
% 97    2
% 98    4
% 99    3
% dtype: int32

s2.value_counts()
% 1    22
% 0    18
% 4    17
% 5    16
% 3    14
% 2    13
% dtype: int64


@
% Since 2 dimensional dataframe doesn't have value_counts(), you should apply it on each column
% df
%   0	1	2	3
% 0	0.0	0.0	3.0	2.0
% 1	3.0	0.0	2.0	1.0
% 2	3.0	2.0	4.0	4.0
% 3	4.0	3.0	4.0	2.0
% Select column 0, then, count the number of appearance of each value
df[0].value_counts()
% 3.0    2
% 4.0    1
% 0.0    1
% Name: 0, dtype: int64


@
% If you want to sort data, you can use sort_index() and sort_values()
% sort_index() sorts data by index value criterions
% sort_values() sorts data by data value criterions

% s2
% 0     5
% 1     3
% 2     4
% 3     0
% 4     1
% 5     3
% 6     5
% 7     0
% 8     0
% 9     1
% 10    4
% 11    5
% 12    4
% 13    1
% 14    2
% 15    4
% 16    5
% 17    2
% 18    4
% 19    3
% 20    4
% 21    2
% 22    4
% 23    5
% 24    2
% 25    4
% 26    1
% 27    1
% 28    0
% 29    5
%      ..
% 70    3
% 71    5
% 72    4
% 73    3
% 74    5
% 75    1
% 76    3
% 77    0
% 78    0
% 79    2
% 80    2
% 81    1
% 82    3
% 83    4
% 84    2
% 85    0
% 86    0
% 87    1
% 88    1
% 89    5
% 90    3
% 91    0
% 92    0
% 93    5
% 94    5
% 95    4
% 96    5
% 97    2
% 98    4
% 99    3
% Length: 100, dtype: int32
% I sort value_counts() of s2 by index criterion  
s2.value_counts().sort_index()
% 0    18
% 1    22
% 2    13
% 3    14
% 4    17
% 5    16
% dtype: int64

% When you sort data by data criterion, if data has NaN, NaN goes to end of order
s.sort_values()
% 0    0.0
% 1    1.0
% 2    2.0
% 4    4.0
% 5    5.0
% 6    6.0
% 7    7.0
% 8    8.0
% 9    9.0
% 3    NaN
% dtype: float64

@
% If you want to sort by data in its descending order,
% you can use ascending=False argument
s.sort_values(ascending=False)
% 9    9.0
% 8    8.0
% 7    7.0
% 6    6.0
% 5    5.0
% 4    4.0
% 2    2.0
% 1    1.0
% 0    0.0
% 3    NaN
% dtype: float64

@
% If you want to use sort_values() on 2 dimensional dataframe,
% you should designate column which will be criterion by "by" argument

% df
%   0	1	2	3
% 0	0.0	0.0	3.0	2.0
% 1	3.0	0.0	2.0	1.0
% 2	3.0	2.0	4.0	NaN
% 3	4.0	3.0	4.0	2.0

% I will use 1 column as criterion column on dataframe df,
% when I sort by value
df.sort_values(by=1)
%   0	1	2	3
% 0	0.0	0.0	3.0	2.0
% 1	3.0	0.0	2.0	1.0
% 2	3.0	2.0	4.0	NaN
% 3	4.0	3.0	4.0	2.0

% If you put list in argument "by", order of element in list will be priority of sort
% So, it first sorts by column 1 then if it runs into same values which can be sorted by first criterion, it uses second criterion
df.sort_values(by=[1, 2])
%   0	1	2	3
% 1	3.0	0.0	2.0	1.0
% 0	0.0	0.0	3.0	2.0
% 2	3.0	2.0	4.0	NaN
% 3	4.0	3.0	4.0	2.0

@
% Practice 2
% 1. Print data of passengers per sex, passengers per age, passengers per class, passengers per dead and alived

@
% You use sum(axis) to find sum of row or sum of column

np.random.seed(1)
df2 = pd.DataFrame(np.random.randint(10, size=(4, 8)))
df2
%   0	1	2	3	4	5	6	7
% 0	5	8	9	5	0	0	1	7
% 1	6	9	2	4	5	2	4	2
% 2	4	7	7	9	1	7	0	6
% 3	9	9	7	6	9	1	0	1

@
% df2
%   0	1	2	3	4	5	6	7
% 0	5	8	9	5	0	0	1	7
% 1	6	9	2	4	5	2	4	2
% 2	4	7	7	9	1	7	0	6
% 3	9	9	7	6	9	1	0	1

% If you want to find sum of row, you use sum(axis=1)
df2.sum(axis=1)
% 0    35
% 1    34
% 2    41
% 3    42
% dtype: int64

% I store df2.sum(axis=1) into value of RowSum key of df2 dataframs
df2["RowSum"] = df2.sum(axis=1)
df2
%   0	1	2	3	4	5	6	7	RowSum
% 0	5	8	9	5	0	0	1	7	35
% 1	6	9	2	4	5	2	4	2	34
% 2	4	7	7	9	1	7	0	6	41
% 3	9	9	7	6	9	1	0	1	42


@
% df2
%   0	1	2	3	4	5	6	7	RowSum
% 0	5	8	9	5	0	0	1	7	35
% 1	6	9	2	4	5	2	4	2	34
% 2	4	7	7	9	1	7	0	6	41
% 3	9	9	7	6	9	1	0	1	42

% If you want to find sum of colum, you can use sum(axis=0)
% But since default of axis is 0, you can omit axis argument
df2.sum()
% 0          24
% 1          33
% 2          25
% 3          24
% 4          15
% 5          10
% 6           5
% 7          16
% RowSum    152
% dtype: int64

df2.loc["ColTotal", :] = df2.sum()
df2
%   0	1	2	3	4	5	6	7	RowSum
% 0	5.0	8.0	9.0	5.0	0.0	0.0	1.0	7.0	35.0
% 1	6.0	9.0	2.0	4.0	5.0	2.0	4.0	2.0	34.0
% 2	4.0	7.0	7.0	9.0	1.0	7.0	0.0	6.0	41.0
% 3	9.0	9.0	7.0	6.0	9.0	1.0	0.0	1.0	42.0
% ColTotal	24.0	33.0	25.0	24.0	15.0	10.0	5.0	16.0	152.0

@

df3 = pd.DataFrame({
        'A': [1, 3, 4, 3, 4],
        'B': [2, 3, 1, 2, 3],
        'C': [1, 5, 2, 4, 4]
    })
df3
%   A	B	C
% 0	1	2	1
% 1	3	3	5
% 2	4	1	2
% 3	3	2	4
% 4	4	3	4

@
% If you want to process more complex manipulation, you can use apply()
% You can pass method taking row or column as argument
% THen, apply() applies each row and each column to that method iteratively 

% You can find difference of between each column,
% you can pass lambda expression into apply()
df3.apply(lambda x: x.max() - x.min())
% A    3
% B    2
% C    4
% dtype: int64

@
% If you want to apply each column to method, you can use axis=1 argument
df3.apply(lambda x: x.max() - x.min(), axis=1)
% 0    1
% 1    2
% 2    3
% 3    2
% 4    1
% dtype: int64

@
% You can pass value_counts()
df3.apply(pd.value_counts)
%   A	B	C
% 1	1.0	1.0	1.0
% 2	NaN	2.0	1.0
% 3	2.0	2.0	NaN
% 4	2.0	NaN	2.0
% 5	NaN	NaN	1.0

@
% You can change NaN to value what you want by using fillna()
% You can change data type of entire data by using astype()
df3.apply(pd.value_counts).fillna(0).astype(int)
%   A	B	C
% 1	1	1	1
% 2	0	2	1
% 3	2	2	0
% 4	2	0	2
% 5	0	0	1

@
% You can convert float value into categorical value

% If you want to convert float value into categorical value by size criterion of float,
% you can use following methods

% cut() is used to make borderline of float value
% qcut() is used when you separate sections which have same unit of size

% Suppose you have following age data
ages = [0, 2, 10, 21, 23, 37, 31, 61, 20, 41, 32, 100]

% You can convert float values into categorical values by using cut()
% bins argument is used as borderline deviding categories
% Values which exceed rage are process as NaN

% 1 teenager 15 youth 25 mature age 35 middle age 60 old 90
bins = [1, 15, 25, 35, 60, 99]
labels = ["teenager", "youth", "mature age", "middle age", "old age"]
cats = pd.cut(ages, bins, labels=labels)
cats
% [NaN, teenager, teenager, youth, youth, ..., old age, youth, mature age, middle age, NaN]
% Length: 12
% Categories (5, object): [teenager < youth < mature age < middle age < old age]

@
% What cut() returns is object of Categorical class
% This object has Categories attribute having label string and codes attributes having category values encoded to integer
type(cats)
% pandas.core.categorical.Categorical
cats.categories
% Index(['teenager', 'youth', 'mature age', 'middle age', 'old age'], dtype='object')
cats.codes
% array([-1,  0,  0,  1,  1,  3,  2,  4,  1,  3,  2, -1], dtype=int8)
df4 = pd.DataFrame(ages, columns=["ages"])
df4["age_cat"] = pd.cut(df4.ages, bins, labels=labels)
df4
%   ages age_cat
% 0	0	NaN
% 1	2	teenager
% 2	10	teenager
% 3	21	youth
% 4	23	youth
% 5	37	middle age
% 6	31	mature age
% 7	61	old age
% 8	20	youth
% 9	41	middle age
% 10 32	mature age
% 11 100 NaN

@
% qcut() doesn't designate borderline
% It separates section that each section has same size of devided data

% We create 1000 size data
data = np.random.randn(1000)
% We makes 4 sections
% And each section has 250 size of data
cats = pd.qcut(data, 4, labels=["Q1", "Q2", "Q3", "Q4"])
cats
% [Q2, Q1, Q2, Q3, Q1, ..., Q1, Q1, Q4, Q4, Q2]
% Length: 1000
% Categories (4, object): [Q1 < Q2 < Q3 < Q4]
pd.value_counts(cats)
% Q4    250
% Q3    250
% Q2    250
% Q1    250
% dtype: int64

@
% Practice 3
% 1. Devide passengers into dead group and alived group
% And on each group, you find each ratio of "teenager", "youth", "mature age", "middle age", "old age"
% Sum of each ratio should be 1       
      </xmp>
   </BODY>
</HTML>
